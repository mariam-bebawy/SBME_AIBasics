{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6229016948897019\n",
      "0.7417869892607294\n",
      "0.7951935655656966\n",
      "0.9424502837770503\n",
      "0.7398985747399307\n",
      "0.922324996665417\n",
      "0.029005228283614737\n",
      "0.46562265437810535\n",
      "0.9433567169983137\n",
      "0.6489745531369242\n"
     ]
    }
   ],
   "source": [
    "# import random\n",
    "from random import Random\n",
    "SEED = 5\n",
    "# random.seed(SEED)\n",
    "random_gen = Random(x = SEED)\n",
    "\n",
    "for _ in range(10):\n",
    "    print(random_gen.uniform(a=0, b=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9009004917506227, 0.11320596465314436, 0.46906904778216374, 0.24657283261983032, 0.5437608592359304, 0.5739411879281008, 0.013114189588902203, 0.21672980046384815, 0.2794823660111103, 0.9163453718085519]\n",
      "[0.06404097169045042, 0.6840484260894295, 0.09280566902857246, 0.06683467116797381, 0.46029284822824157, 0.6488731319048344, 0.8920692618273897, 0.7208649653128105, 0.06935832617007243, 0.6431179618819661]\n"
     ]
    }
   ],
   "source": [
    "def generate_pts_comp(N = 1000):\n",
    "    return(\n",
    "        [ random_gen.uniform(a=0, b=1) for _ in range(N) ], \n",
    "        [ random_gen.uniform(a=0, b=1) for _ in range(N) ]\n",
    "    )\n",
    "\n",
    "data_x, data_y = generate_pts_comp()\n",
    "print(data_x[:10])\n",
    "print(data_y[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *previous implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def loss(x_p, y_p):\n",
    "    return (1 / len(data_x)) * sum(\n",
    "        [sqrt((x_i - x_p)**2 + (y_i - y_p)**2)\n",
    "        for x_i, y_i in zip(data_x, data_y)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_p, y_p = 5, 5\n",
    "EPOCHS = 3000\n",
    "DELTA = 0.01\n",
    "H = 0.001\n",
    "\n",
    "epoch_losses = []\n",
    "for _ in range(EPOCHS):\n",
    "    epoch_losses.append(loss(x_p, y_p))\n",
    "    dloss_dx = (loss(x_p + H, y_p) - loss(x_p, y_p)) / H\n",
    "    dloss_dy = (loss(x_p, y_p + H) - loss(x_p, y_p)) / H\n",
    "    x_p -= DELTA * dloss_dx\n",
    "    y_p -= DELTA * dloss_dy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *closed form evaluation of gradient*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(x_p, y_p):\n",
    "    sum_x, sum_y = 0., 0.\n",
    "    for x_i, y_i in zip(data_x, data_y):\n",
    "        inv_sqrt = ((x_i - x_p)**2 + (y_i - y_p)**2) ** -0.5\n",
    "        sum_x += inv_sqrt * (x_i - x_p)\n",
    "        sum_y += inv_sqrt * (y_i - y_p)\n",
    "        return - sum_x / len(data_x), - sum_y / len(data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Closed form : (0.000638877362694616, 0.0007693085957120017) \n",
      " Original definition : 0.7064617140990492, 0.7063225228360892 \n"
     ]
    }
   ],
   "source": [
    "x_p, y_p = 5, 5\n",
    "H = 0.001\n",
    "\n",
    "dloss_dx = (loss(x_p + H, y_p) - loss(x_p, y_p)) / H\n",
    "dloss_dy = (loss(x_p, y_p + H) - loss(x_p, y_p)) / H\n",
    "\n",
    "print(f\" Closed form : {calc_grad(x_p, y_p)} \")\n",
    "print(f\" Original definition : {dloss_dx}, {dloss_dy} \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *automated differentiation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import {\n",
    "    tensor, \n",
    "    sum as torch_sum, \n",
    "    rand, \n",
    "    no_grad\n",
    "}\n",
    "from torch.random import manual_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "gen = manual_seed(5)\n",
    "data = rand(size=(1000, 2), generator=gen)\n",
    "\n",
    "print(type(data), data.shape, data[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = lambda pnt : torch_sum(torch_sum((data - pnt)**2, dim=1)**5)\n",
    "pnt = tensor((5., 5.))      # initialization\n",
    "pnt.requires_grad = True\n",
    "for _ in range(1000):\n",
    "    curr_loss = loss(pnt)\n",
    "    curr_loss.backward()    # backward propagation of gradient\n",
    "    with no_grad():         # keep for later\n",
    "        pnt -= 0.001 * pnt.grad.data    # gradient was calculated\n",
    "        pnt.grad.zero()     # zero the gradient     # more later\n",
    "\n",
    "print(pnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
